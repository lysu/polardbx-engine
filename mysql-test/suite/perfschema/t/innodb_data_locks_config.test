--disable_query_log
call mtr.add_suppression("The transaction .* holds too many locks which exceeds the configured pfs_data_locks_max_locks_per_batch");
--enable_query_log

CREATE TABLE t1 (id INT PRIMARY KEY) Engine=InnoDB;
INSERT INTO t1 VALUES (0),(10),(20),(30),(40),(50),(60),(70),(80),(90);

--connect (C1, localhost, root,,)
--connect (C2, localhost, root,,)
--connect (C3, localhost, root,,)
--connect (C4, localhost, root,,)

--connection C1
  BEGIN;
  SELECT * FROM t1 where id<=50 FOR UPDATE;

--connection C2
  START TRANSACTION READ ONLY;
  SELECT * FROM t1 where id>=60 and id<=90 LOCK IN SHARE MODE;

--connection C3
  START TRANSACTION READ ONLY;
  SELECT * FROM t1 where id=70 LOCK IN SHARE MODE;

sleep 5;

--connection C4
  START TRANSACTION READ ONLY;
  SELECT * FROM t1 where id=80 LOCK IN SHARE MODE;

--connection default
  SELECT
    object_name,
    index_name,
    lock_type,
    lock_mode,
    lock_status,
    lock_data
  FROM performance_schema.data_locks
  ORDER BY 1,2,3;

  SET GLOBAL innodb_pfs_data_locks_max_locks_per_batch = 3;
  SELECT
    object_name,
    index_name,
    lock_type,
    lock_mode,
    lock_status,
    lock_data
  FROM performance_schema.data_locks
  ORDER BY 1,2,3;

--connection C1
  ROLLBACK;
--connection C2
  ROLLBACK;
--connection C3
  ROLLBACK;
--connection C4
  ROLLBACK;

--connection default
--disconnect C1
--disconnect C2
--disconnect C3
--disconnect C4
SET GLOBAL innodb_pfs_data_locks_max_locks_per_batch = default;
DROP TABLE t1;